{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5369183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/genesis/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from toolformer_pytorch import Toolformer, PaLM\n",
    "\n",
    "from transformers import GPTJForCausalLM\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94dd1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calendar():\n",
    "    import datetime\n",
    "    from calendar import day_name, month_name\n",
    "    now = datetime.datetime.now()\n",
    "    return f'Today is {day_name[now.weekday()]}, {month_name[now.month]} {now.day}, {now.year}.'\n",
    "\n",
    "# prompt for teaching it to use the Calendar function from above\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to add calls to a Calendar API to a piece of text.\n",
    "The API calls should help you get information required to complete the text.\n",
    "You can call the API by writing \"[Calendar()]\"\n",
    "Here are some examples of API calls:\n",
    "Input: Today is the first Friday of the year.\n",
    "Output: Today is the first [Calendar()] Friday of the year.\n",
    "Input: The president of the United States is Joe Biden.\n",
    "Output: The president of the United States is [Calendar()] Joe Biden.\n",
    "Input: [input]\n",
    "Output: \n",
    "\"\"\"\n",
    "\n",
    "data = [\n",
    "    \"The store is never open on the weekend, so today it is closed.\",\n",
    "    \"The number of days from now until Christmas is 30\",\n",
    "    \"The current day of the week is Wednesday.\",\n",
    "]\n",
    "\n",
    "# model - here using PaLM, but any nn.Module that returns logits in the shape (batch, seq, num_tokens) is fine\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").cuda()\n",
    "\n",
    "# model = PaLM(\n",
    "#     dim = 512,\n",
    "#     depth = 2,\n",
    "#     heads = 8,\n",
    "#     dim_head = 64\n",
    "# ).cuda()\n",
    "\n",
    "# toolformer\n",
    "\n",
    "toolformer = Toolformer(\n",
    "    model = model,\n",
    "    model_seq_len = 256,\n",
    "    teach_tool_prompt = prompt,\n",
    "    tool_id = 'Calendar',\n",
    "    tool = Calendar,\n",
    "    finetune = True,\n",
    "    tokenizer_encode=tokenizer.encode,\n",
    "    tokenizer_decode=tokenizer.decode,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bff8607",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The store is never open on the weekend, so today it is closed.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b4c3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits shape: torch.Size([3, 257, 49408])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "650aead3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:08<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/genesis/fun/toolformer/toolformer-pytorch/toolformer_pytorch/toolformer_pytorch.py\u001b[0m(888)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    887 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 888 \u001b[0;31m        \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data_with_api_calls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'your model failed to follow instructions and make API calls. please try a better model or do some better prompt engineering'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    889 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "your model failed to follow instructions and make API calls. please try a better model or do some better prompt engineering",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-71024cdceac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# (5) fine-tune on the filtered results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfiltered_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# then, once you see the 'finetune complete' message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fun/toolformer/toolformer-pytorch/toolformer_pytorch/toolformer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, return_after_generating_api_calls, return_after_making_api_calls, return_after_filtering_api_calls, return_after_filtering_by_api_response)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data_with_api_calls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'your model failed to follow instructions and make API calls. please try a better model or do some better prompt engineering'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mdata_with_responses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_api_calls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data_with_api_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: your model failed to follow instructions and make API calls. please try a better model or do some better prompt engineering"
     ]
    }
   ],
   "source": [
    "# invoking this will\n",
    "# (1) prompt the model with your inputs (data), inserted into [input] tag\n",
    "# (2) with the sampled outputs, filter out the ones that made proper API calls\n",
    "# (3) execute the API calls with the `tool` given\n",
    "# (4) filter with the specialized filter function (which can be used independently as shown in the next section)\n",
    "# (5) fine-tune on the filtered results\n",
    "\n",
    "filtered_stats = toolformer(data)\n",
    "\n",
    "# then, once you see the 'finetune complete' message\n",
    "\n",
    "response = toolformer.sample_model_with_api_calls(\"How many days until the next new years?\")\n",
    "\n",
    "# hopefully you see it invoke the calendar and utilize the response of the api call..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cdf1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1d796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
